{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d7ac6d-e2ed-4c9f-ba68-c48bf984ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahes\\anaconda3\\envs\\mp310\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\mahes\\anaconda3\\envs\\mp310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe available.\n",
      "Loading Whisper small...\n",
      "Small loaded.\n",
      "Loading Whisper medium...\n",
      "Medium loaded.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  Mahesh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome Mahesh! Upload your resume.\n",
      "Resume successfully uploaded.\n",
      "\n",
      "\n",
      "Question 1/5: Introduce yourself.\n",
      "Answer: Good afternoon. This is Mahesh and I am from Jannagam. First of all, thank you for giving this wonderful opportunity to introduce myself. I'm passionate about data and technology and have developed skills in Python, SQL, data analytics, machine learning, deep learning and generate to AI. Thank you.\n",
      "Feedback: Nice to meet you, Mahesh.\n",
      "\n",
      "Question 2/5: Explain overfitting; how would you detect and prevent it in a model?\n",
      "Answer: Overfitting means when the trainer crazy is more than the tester crazy it occurs overfitting problem. When we use L1, L2, regularization techniques to reduce the overfitting problem in regression problems. When I come to the deep learning we use dropout technique and hyperparametric tuning.\n",
      "Feedback: Good explanation of overfitting, detection, and prevention techniques!\n",
      "\n",
      "Question 3/5: Describe your experience applying TF-IDF for text vectorization in a previous project\n",
      "Answer: Yeah, using TFIDF to convert text to numerical data.\n",
      "Feedback: Concise! TF-IDF is a great choice for text vectorization.\n",
      "\n",
      "Question 4/5: Explain a project where you chose and justified a specific ML evaluation metric\n",
      "Answer: Yeah, I suppose the project is always price prediction in the in that project. The output is price means it is a continuous data. So we go through the regression algorithm. I mean, technique. So in this project, lastly, we find out the evolution metrics like accuracy, cross violation score, time, RMSE. That's it. Thank you.\n",
      "Feedback: Clear explanation, good justification of metrics, concise summary.\n",
      "\n",
      "Question 5/5: Describe a challenging ML project where you had to adapt your approach\n",
      "Answer: Sorry, I don't know.\n",
      "Feedback: Concise! Signals honesty and willingness to learn.\n",
      "\n",
      "Interview Completed.\n"
     ]
    }
   ],
   "source": [
    "# ================= AI INTERVIEW SYSTEM =================\n",
    "# Features:\n",
    "# - Uses MediaPipe for face landmarks\n",
    "# - Captures audio reliably\n",
    "# - Hybrid Whisper transcription (small → medium)\n",
    "# - Gemini generates next questions from JD + Resume\n",
    "# - Non-blocking TTS feedback while webcam live\n",
    "# - Draws only main face contours (eyes/lips/outline)\n",
    "# ======================================================\n",
    "\n",
    "import os, time, queue, threading, contextlib, tempfile, re\n",
    "import sounddevice as sd               # for audio recording\n",
    "from scipy.io.wavfile import write, read\n",
    "import cv2, numpy as np                # for webcam display and image ops\n",
    "\n",
    "# ---------------- Whisper (ASR) ----------------\n",
    "try:\n",
    "    import whisper                     # Whisper automatic speech recognition\n",
    "except:\n",
    "    whisper = None\n",
    "\n",
    "# ---------------- TTS ----------------\n",
    "try:\n",
    "    import pyttsx3                     # text-to-speech (local)\n",
    "    TTS_AVAILABLE = True\n",
    "except:\n",
    "    pyttsx3 = None\n",
    "    TTS_AVAILABLE = False\n",
    "\n",
    "# ---------------- Gemini AI ----------------\n",
    "try:\n",
    "    import google.generativeai as genai     # Gemini API (if available)\n",
    "    GEMINI_AVAILABLE = True\n",
    "except:\n",
    "    genai = None\n",
    "    GEMINI_AVAILABLE = False\n",
    "\n",
    "# ---------------- Resume Parsing ----------------\n",
    "import PyPDF2, docx                     # PDF / DOCX reading\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "# ---------------- MediaPipe setup ----------------\n",
    "# We rely on MediaPipe. If MediaPipe is missing, the program will still show the webcam\n",
    "# feed but no face landmark drawing will be performed.\n",
    "MP_AVAILABLE = False\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    MP_AVAILABLE = True\n",
    "    print(\"MediaPipe available.\")\n",
    "except Exception as e:\n",
    "    # For beginners: MediaPipe is optional here. If not installed, the app still runs\n",
    "    # but face contours won't be drawn.\n",
    "    print(\"MediaPipe not available:\", e)\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "AUDIO_FILENAME = os.path.join(tempfile.gettempdir(), \"candidate_answer.wav\")\n",
    "SAMPLE_RATE = 16000                     # audio sampling rate (Hz)\n",
    "SILENCE_DURATION = 10.0                 # seconds of silence to auto-stop recording\n",
    "SILENCE_THRESHOLD = 0.005               # RMS threshold for detecting speech\n",
    "WIN_W, WIN_H = 960, 540                 # window size for display\n",
    "MAX_QUESTION_WORDS = 14                 # limit for generated questions\n",
    "TECH_QUESTIONS = 3\n",
    "HR_QUESTIONS = 1\n",
    "TOTAL_QUESTIONS = 1 + TECH_QUESTIONS + HR_QUESTIONS\n",
    "GEN_RETRY = 1                           # how many times to retry Gemini generation\n",
    "\n",
    "# ---------------- Whisper models load ----------------\n",
    "whisper_small, whisper_medium = None, None\n",
    "if whisper:\n",
    "    try:\n",
    "        print(\"Loading Whisper small...\")\n",
    "        whisper_small = whisper.load_model(\"small\")\n",
    "        print(\"Small loaded.\")\n",
    "    except:\n",
    "        whisper_small = None\n",
    "    try:\n",
    "        print(\"Loading Whisper medium...\")\n",
    "        whisper_medium = whisper.load_model(\"medium\")\n",
    "        print(\"Medium loaded.\")\n",
    "    except:\n",
    "        whisper_medium = None\n",
    "\n",
    "# ---------------- TTS async speak ----------------\n",
    "def speak_async(text):\n",
    "    \"\"\"\n",
    "    Speak text using pyttsx3 in a background thread so the webcam remains live.\n",
    "    If pyttsx3 is not available, just print the text.\n",
    "    \"\"\"\n",
    "    done = threading.Event()\n",
    "    if not TTS_AVAILABLE:\n",
    "        print(\"AI:\", text)\n",
    "        done.set()\n",
    "        return done\n",
    "\n",
    "    def _run():\n",
    "        try:\n",
    "            engine = pyttsx3.init()\n",
    "            engine.setProperty('rate', 170)   # speak rate\n",
    "            engine.say(str(text))\n",
    "            engine.runAndWait()\n",
    "        finally:\n",
    "            done.set()\n",
    "\n",
    "    threading.Thread(target=_run, daemon=True).start()\n",
    "    return done\n",
    "\n",
    "# ---------------- Text helpers ----------------\n",
    "def clean_text(t):\n",
    "    \"\"\"Remove non-ASCII chars and extra whitespace.\"\"\"\n",
    "    if t is None:\n",
    "        return \"\"\n",
    "    t = re.sub(r'[^\\x00-\\x7F]+', ' ', str(t))\n",
    "    return re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "def wrap_text(text, max_chars=40):\n",
    "    \"\"\"Wrap text into multiple lines for display on the frame.\"\"\"\n",
    "    if not text:\n",
    "        return [\"\"]\n",
    "    words = text.split()\n",
    "    lines, cur = [], \"\"\n",
    "    for w in words:\n",
    "        if len((cur + \" \" + w).strip()) <= max_chars:\n",
    "            cur = (cur + \" \" + w).strip()\n",
    "        else:\n",
    "            lines.append(cur)\n",
    "            cur = w\n",
    "    if cur:\n",
    "        lines.append(cur)\n",
    "    return lines\n",
    "\n",
    "# ---------------- Resume extractors ----------------\n",
    "def extract_text_from_pdf(path):\n",
    "    \"\"\"Return text extracted from PDF (basic).\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            r = PyPDF2.PdfReader(f)\n",
    "            for p in r.pages:\n",
    "                text += (p.extract_text() or \"\") + \"\\n\"\n",
    "    except:\n",
    "        pass\n",
    "    return clean_text(text)\n",
    "\n",
    "def extract_text_from_docx(path):\n",
    "    \"\"\"Return text extracted from DOCX (basic).\"\"\"\n",
    "    try:\n",
    "        d = docx.Document(path)\n",
    "        return clean_text(\"\\n\".join(p.text for p in d.paragraphs if p.text.strip()))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_file(path):\n",
    "    \"\"\"Auto-detect file type and extract text; supports PDF and DOCX.\"\"\"\n",
    "    if not path:\n",
    "        return \"\"\n",
    "    p = path.lower()\n",
    "    if p.endswith(\".pdf\"):\n",
    "        return extract_text_from_pdf(path)\n",
    "    if p.endswith((\".doc\", \".docx\")):\n",
    "        return extract_text_from_docx(path)\n",
    "    return \"\"\n",
    "\n",
    "# ---------------- Audio recording ----------------\n",
    "def record_audio(stop_flag, filename=AUDIO_FILENAME):\n",
    "    \"\"\"\n",
    "    Record audio from default microphone until:\n",
    "    - stop_flag['next'] is set by caller (e.g., user pressed a key), OR\n",
    "    - a long silence is detected after speech.\n",
    "    Audio is saved to `filename`.\n",
    "    \"\"\"\n",
    "    q_audio = queue.Queue()\n",
    "    frames = []\n",
    "    last_loud = time.time()\n",
    "    speech_started = False\n",
    "\n",
    "    def _cb(indata, frames_count, time_info, status):\n",
    "        # callback from sounddevice: push audio chunk into queue\n",
    "        q_audio.put(indata.copy())\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, callback=_cb):\n",
    "            while not stop_flag[\"next\"]:\n",
    "                try:\n",
    "                    data = q_audio.get(timeout=0.05)\n",
    "                    frames.append(data)\n",
    "\n",
    "                    # compute RMS to detect if user is speaking\n",
    "                    rms = np.sqrt(np.mean(data**2))\n",
    "                    if rms > SILENCE_THRESHOLD:\n",
    "                        speech_started = True\n",
    "                        last_loud = time.time()\n",
    "                    elif speech_started and (time.time() - last_loud) > SILENCE_DURATION:\n",
    "                        stop_flag[\"next\"] = True\n",
    "                except queue.Empty:\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        print(\"Audio issue:\", e)\n",
    "\n",
    "    # if we recorded frames, save them to WAV\n",
    "    if frames:\n",
    "        audio = np.concatenate(frames, axis=0).flatten()\n",
    "        audio /= (np.max(np.abs(audio)) + 1e-9)\n",
    "        write(filename, SAMPLE_RATE, (audio * 32767).astype(np.int16))\n",
    "\n",
    "# ---------------- Transcription ----------------\n",
    "def transcribe_audio(filename=AUDIO_FILENAME):\n",
    "    \"\"\"\n",
    "    Transcribe WAV using loaded Whisper model (small preferred, else medium).\n",
    "    Returns plain text. If no model present or file missing, returns \"\".\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        return \"\"\n",
    "    if whisper_small is None and whisper_medium is None:\n",
    "        return \"\"\n",
    "    model = whisper_small or whisper_medium\n",
    "    with contextlib.redirect_stdout(None):\n",
    "        try:\n",
    "            r = model.transcribe(filename, fp16=False, language=\"en\")\n",
    "        except:\n",
    "            return \"\"\n",
    "    return clean_text(r.get(\"text\", \"\"))\n",
    "\n",
    "# ---------------- Gemini config ----------------\n",
    "GEMINI_API_KEY = \"AIzaSyDePhGmZ_nIoS8ibafMFTXCiI-HiTuGf08\"  # keep/update as needed\n",
    "gen_model = None\n",
    "if GEMINI_AVAILABLE and GEMINI_API_KEY:\n",
    "    try:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        gen_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    except Exception as e:\n",
    "        print(\"Gemini init failed:\", e)\n",
    "\n",
    "# ---------------- AI question generator ----------------\n",
    "def generate_next_question_background(jd_summary, resume_text, used_set, container, role):\n",
    "    \"\"\"\n",
    "    Ask Gemini to generate ONE short interview question given JD + resume.\n",
    "    The result is written to container[0] (thread-safe small container).\n",
    "    \"\"\"\n",
    "    jd_short = jd_summary[:800] + \"...\" if len(jd_summary) > 800 else jd_summary\n",
    "    resume_short = resume_text[:1200] + \"...\" if len(resume_text) > 1200 else resume_text\n",
    "\n",
    "    prompt = (\n",
    "        f\"Generate ONE {role} interview question \"\n",
    "        f\"(max {MAX_QUESTION_WORDS} words). JD: {jd_short}. Resume: {resume_short}. Previous: {list(used_set)}.\"\n",
    "    )\n",
    "\n",
    "    if gen_model is None:\n",
    "        container[0] = None\n",
    "        return\n",
    "\n",
    "    for _ in range(GEN_RETRY):\n",
    "        try:\n",
    "            r = gen_model.generate_content(prompt)\n",
    "            q = clean_text(r.text.split(\"\\n\")[0])\n",
    "            q = re.sub(r'^(question\\s*\\d*[:\\-]?)','', q, flags=re.I).strip().split('.')[0].strip()\n",
    "            if q and q not in used_set:\n",
    "                used_set.add(q)\n",
    "                container[0] = q\n",
    "                return\n",
    "        except Exception:\n",
    "            time.sleep(0.3)\n",
    "\n",
    "    container[0] = None\n",
    "\n",
    "# ---------------- AI feedback generation ----------------\n",
    "def generate_feedback(question, answer):\n",
    "    \"\"\"Ask Gemini for a short positive feedback sentence for the answer.\"\"\"\n",
    "    if not gen_model:\n",
    "        return \"Thank you for your answer.\"\n",
    "    prompt = (\n",
    "        f\"Provide brief positive feedback (max 10 words) \"\n",
    "        f\"on '{answer}' for '{question}'. Only positive.\"\n",
    "    )\n",
    "    try:\n",
    "        r = gen_model.generate_content(prompt)\n",
    "        fb = clean_text(r.text.split(\"\\n\")[0])\n",
    "        return fb or \"Thank you for your answer.\"\n",
    "    except:\n",
    "        return \"Thank you for your answer.\"\n",
    "\n",
    "# ---------------- First question fixed feedback ----------------\n",
    "def generate_first_answer_feedback(candidate_name, candidate_answer):\n",
    "    \"\"\"\n",
    "    Per your request: ALWAYS return a fixed greeting for the first question.\n",
    "    This ensures the first feedback is exactly \"Nice to meet you, {candidate}\".\n",
    "    \"\"\"\n",
    "    return f\"Nice to meet you, {candidate_name}.\"\n",
    "\n",
    "# ---------------- Draw face contours (MediaPipe) ----------------\n",
    "def draw_full_mesh_points(frame, face_landmarks):\n",
    "    \"\"\"\n",
    "    Draw a simplified set of facial contours (outline, eyes, lips) using\n",
    "    MediaPipe face landmarks. For beginners: face_landmarks is provided by MediaPipe.\n",
    "    \"\"\"\n",
    "    ih, iw = frame.shape[:2]\n",
    "\n",
    "    FACE_OUTLINE = [10,338,297,332,284,251,389,356,454,323,361,288,\n",
    "                    397,365,379,378,400,377,152,148,176,149,150,\n",
    "                    136,172,58,132,93,234,127,162,21,54,103,67,109]\n",
    "    LEFT_EYE  = [33,160,158,133,153,144]\n",
    "    RIGHT_EYE = [263,387,385,362,380,373]\n",
    "    OUTER_LIPS = [61,146,91,181,84,17,314,405,321,375,291,308]\n",
    "    INNER_LIPS = [78,95,88,178,87,14,317,402,318,324]\n",
    "\n",
    "    def line(points, color):\n",
    "        for i in range(len(points)-1):\n",
    "            x1 = int(points[i].x * iw)\n",
    "            y1 = int(points[i].y * ih)\n",
    "            x2 = int(points[i+1].x * iw)\n",
    "            y2 = int(points[i+1].y * ih)\n",
    "            cv2.line(frame, (x1,y1), (x2,y2), color, 1)\n",
    "\n",
    "    lm = face_landmarks.landmark\n",
    "    line([lm[i] for i in FACE_OUTLINE], (255,255,0))\n",
    "    line([lm[i] for i in LEFT_EYE],    (0,255,0))\n",
    "    line([lm[i] for i in RIGHT_EYE],   (0,255,0))\n",
    "    line([lm[i] for i in OUTER_LIPS],  (0,0,255))\n",
    "    line([lm[i] for i in INNER_LIPS],  (0,100,255))\n",
    "\n",
    "# ---------------- Main Interview Flow ----------------\n",
    "def run_interview():\n",
    "    \"\"\"\n",
    "    Main entry: ask candidate name, upload resume, then proceed through\n",
    "    a sequence of questions with webcam, audio capture, transcription,\n",
    "    feedback and generated next questions.\n",
    "    \"\"\"\n",
    "    # Ask candidate name and request resume\n",
    "    candidate = input(\"Enter your name: \").strip() or \"Candidate\"\n",
    "    print(f\"Welcome {candidate}! Upload your resume.\")\n",
    "    speak_async(\"Please upload your resume.\")\n",
    "\n",
    "    Tk().withdraw()\n",
    "    resume_path = askopenfilename(title=\"Select Resume\", filetypes=[(\"Documents\",\"*.pdf *.docx\")])\n",
    "    resume_text = extract_text_from_file(resume_path) if resume_path else \"\"\n",
    "    print(\"Resume successfully uploaded.\\n\")\n",
    "\n",
    "    # A simple job description summary used to steer question generation\n",
    "    jd_summary = \"We are looking for a motivated AI/ML Engineer with 1–3 years of experience in ML projects.\"\n",
    "\n",
    "    used = set()                        # keep track of used questions\n",
    "    current_q = \"Introduce yourself.\"   # fixed first question\n",
    "    used.add(current_q)\n",
    "\n",
    "    # Open webcam window\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open webcam.\")\n",
    "        return\n",
    "\n",
    "    cv2.namedWindow(\"AI Interview\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"AI Interview\", WIN_W, WIN_H)\n",
    "\n",
    "    # Initialize MediaPipe FaceMesh if available\n",
    "    face_mesh_instance = None\n",
    "    if MP_AVAILABLE:\n",
    "        face_mesh_instance = mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1, refine_landmarks=False,\n",
    "            min_detection_confidence=0.5, min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    all_answers = []\n",
    "    total_qs = TOTAL_QUESTIONS\n",
    "\n",
    "    try:\n",
    "        for q_index in range(1, total_qs + 1):\n",
    "            # Show and speak the question\n",
    "            print(f\"\\nQuestion {q_index}/{total_qs}: {current_q}\")\n",
    "            q_speak_evt = speak_async(f\"Question {q_index}. {current_q}\")\n",
    "\n",
    "            # Keep webcam live while TTS speaks the question\n",
    "            while not q_speak_evt.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "\n",
    "                # Display wrapped question text on frame\n",
    "                wrapped = wrap_text(current_q, 40)\n",
    "                y0 = 30\n",
    "                for line in wrapped:\n",
    "                    cv2.putText(frame, line, (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "                    y0 += 30\n",
    "\n",
    "                cv2.putText(frame, \"Listening shortly... (press 'q' to skip)\", (20, WIN_H - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,200), 1)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF in [ord('q'), 27]:\n",
    "                    break\n",
    "\n",
    "            # Start recording in background\n",
    "            stop_flag = {\"next\": False}\n",
    "            rec_thread = threading.Thread(target=record_audio, args=(stop_flag,), daemon=True)\n",
    "            rec_thread.start()\n",
    "\n",
    "            # While recording, show webcam and draw MediaPipe landmarks only if available\n",
    "            while not stop_flag[\"next\"]:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "\n",
    "                # MEDIAPIPE ONLY: if available, detect and draw face landmarks\n",
    "                if MP_AVAILABLE and face_mesh_instance is not None:\n",
    "                    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    results = face_mesh_instance.process(rgb)\n",
    "                    if results.multi_face_landmarks:\n",
    "                        for face_landmarks in results.multi_face_landmarks:\n",
    "                            draw_full_mesh_points(frame, face_landmarks)\n",
    "                # If MediaPipe is NOT available: we intentionally do NOT perform any face detection.\n",
    "                # This keeps the code simple and avoids Haar cascades entirely.\n",
    "\n",
    "                # Display the question text and recording status\n",
    "                wrapped = wrap_text(current_q, 40)\n",
    "                y0 = 30\n",
    "                for line in wrapped:\n",
    "                    cv2.putText(frame, line, (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "                    y0 += 30\n",
    "\n",
    "                cv2.putText(frame, \"Recording... (press 'q' to stop)\", (20, WIN_H - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 1)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key in [ord('q'), 27]:\n",
    "                    stop_flag[\"next\"] = True\n",
    "                    break\n",
    "\n",
    "            # Ensure recording thread finishes\n",
    "            if rec_thread.is_alive():\n",
    "                rec_thread.join(timeout=1.0)\n",
    "\n",
    "            # Transcribe in background\n",
    "            transcription = {\"text\": \"\"}\n",
    "            trans_done_flag = threading.Event()\n",
    "            def _transcribe():\n",
    "                transcription[\"text\"] = transcribe_audio(AUDIO_FILENAME)\n",
    "                trans_done_flag.set()\n",
    "            threading.Thread(target=_transcribe, daemon=True).start()\n",
    "\n",
    "            # Keep webcam live while transcription happens\n",
    "            while not trans_done_flag.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                cv2.putText(frame, \"Processing answer...\", (20,40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "            answer_text = transcription[\"text\"]\n",
    "            print(\"Answer:\", answer_text)\n",
    "            all_answers.append(answer_text)\n",
    "\n",
    "            # Generate feedback (first question fixed greeting; others via Gemini)\n",
    "            fb_container = [None]\n",
    "            fb_done = threading.Event()\n",
    "            def _gen_feedback():\n",
    "                try:\n",
    "                    if q_index == 1:\n",
    "                        fb = generate_first_answer_feedback(candidate, answer_text)\n",
    "                    else:\n",
    "                        fb = generate_feedback(current_q, answer_text)\n",
    "                    fb_container[0] = fb\n",
    "                finally:\n",
    "                    fb_done.set()\n",
    "            threading.Thread(target=_gen_feedback, daemon=True).start()\n",
    "\n",
    "            # Keep webcam live while feedback being generated\n",
    "            while not fb_done.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                cv2.putText(frame, \"Generating feedback...\", (20,40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,200,200), 2)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "            feedback = fb_container[0] or \"Thank you for your answer.\"\n",
    "            print(\"Feedback:\", feedback)\n",
    "            speak_evt = speak_async(feedback)\n",
    "\n",
    "            # Keep webcam live while feedback is spoken\n",
    "            while not speak_evt.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                cv2.putText(frame, \"Speaking feedback...\", (20,40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (180,180,255), 2)\n",
    "                cv2.imshow(\"AI Interview\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "            # Prepare next question (if not last)\n",
    "            if q_index < total_qs:\n",
    "                next_container = [None]\n",
    "                nq_done = threading.Event()\n",
    "                def _gen_nextq():\n",
    "                    try:\n",
    "                        role = \"Technical\" if q_index <= TECH_QUESTIONS else \"HR\"\n",
    "                        generate_next_question_background(jd_summary, resume_text, used, next_container, role)\n",
    "                    finally:\n",
    "                        nq_done.set()\n",
    "                threading.Thread(target=_gen_nextq, daemon=True).start()\n",
    "\n",
    "                # Keep webcam live while next question generation is in progress\n",
    "                while not nq_done.is_set():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        continue\n",
    "                    cv2.putText(frame, \"Preparing next question...\", (20,40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200,200,100), 2)\n",
    "                    cv2.imshow(\"AI Interview\", frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == 27:\n",
    "                        break\n",
    "\n",
    "                # If Gemini fails, use a reasonable fixed next question based on role.\n",
    "                role_fallback = \"Technical\" if q_index <= TECH_QUESTIONS else \"HR\"\n",
    "                current_q = next_container[0] or (\n",
    "                    \"Tell me about a project from your resume.\" if role_fallback == \"Technical\"\n",
    "                    else \"Why do you want to join our company?\"\n",
    "                )\n",
    "                used.add(current_q)\n",
    "\n",
    "    finally:\n",
    "        # cleanup\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        if MP_AVAILABLE and face_mesh_instance:\n",
    "            face_mesh_instance.close()\n",
    "\n",
    "    print(\"\\nInterview Completed.\")\n",
    "    speak_async(f\"Thank you for the interview, {candidate}.\")\n",
    "\n",
    "# ---------------- Main entry ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_interview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6573a4c-2213-4c8f-abe3-cc93def8f3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (MediaPipe)",
   "language": "python",
   "name": "mp310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
